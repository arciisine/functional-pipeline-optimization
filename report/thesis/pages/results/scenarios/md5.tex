\subsection{\mdfive}
The \mdfive algorithm \cite{mdfive92} is a hashing algorithm that generates a 128-bit signature for any input of bytes. This algorithm is computationally heavy. A unique feature of this test, is that it is the only one in which the manual form was pulled from a preexisting library that had already optimized heavily for cpu performance.

Looking at the results, the general trend is the optimized code outperforming the functional form, and the manual transformation outperforming the optimized code.  The graphs reveal some more detailed analysis with respect to specific performance characteristics.

Looking at \ref{fig:md5:1..100000..5000x2}, this test highlights variability in code that deals with large amount of input, but is run infrequently. As compared to the other graphs, this graph shows the least consistency in time per array element. The underlying engine will be affected greatly by its internal caches, and hotspot optimizations. Overall the ordering of the implementation efficiency holds true, but there is a point where the functional form outperformed the optimized form even at 10k iterations. 

With \ref{fig:md5:2x1..100000..5000}, this test highlights how the scenario handles the overhead of the optimization process, as the frequency of iteration inside the generated code is much less than the frequency of execution of the generated code. The overall performance at 1 iteration does not have enough iterations to amortize the startup costs.  At iteration count 5000 and beyond you can see the code generally runs at the same cost per array element.  

Comparing the input size focused figures (\ref{fig:md5:1..100000..5000x10}, \ref{fig:md5:1..100000..5000x100}) versus the iteration focused figures (\ref{fig:md5:10x1..100000..5000}, \ref{fig:md5:100x1..100000..5000}) it is apparent that the cost per iteration is much lower when the input size increases as opposed to the number of iterations. This points to the underlying engine being able to optimize tight loops better than repeated function invocations.  Comparing \ref{fig:md5:1..100000..5000x100} with \ref{fig:md5:100x1..100000..5000}, the times per array element start to converge.  This would imply that there is some minimal threshold that reaps the full benefit ot the underlying engine's hotspot optimizations. 

What is also clear, is that from the functional form to the optimized functional form, there is a dramatic increase in performance.  What we see is about a 10x speedup between the optimized and non-optimized algorithm, and about a 3x speedup between the optimized and manual implementations. 